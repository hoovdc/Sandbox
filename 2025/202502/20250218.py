#Notion_Gcal_TotalTime_standalone.py
#Aggegregates Google Calendar event times and Notion task times
#Generated by Cursor using Claude 3.5 Sonnet
import os
import datetime
import pytz
from google.auth.transport.requests import Request
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from googleapiclient.discovery import build
import json
import plotly.graph_objects as go
import asyncio
import aiohttp
import sqlite3
import os.path
from pathlib import Path
from notion_client import Client
import pandas as pd
from typing import Any

# Configuration Constants
NOTION_API_VERSION = "2022-06-28"
SCOPES = ['https://www.googleapis.com/auth/calendar.readonly']
QUESTIONABLE_WORDS = ["?", "tbd", "canx", "//", "prev complete"]
START_DATE = datetime.date(2024, 1, 1)  # Generic start date

def get_config_paths():
    """Get configuration paths from environment variables or default locations"""
    base_dir = os.getenv('TIME_TRACKER_BASE_DIR', str(Path(__file__).parent))
    secrets_dir = os.getenv('TIME_TRACKER_SECRETS_DIR', os.path.join(base_dir, 'secrets'))
    data_dir = os.getenv('TIME_TRACKER_DATA_DIR', os.path.join(base_dir, 'data'))
    
    return {
        'base_dir': Path(base_dir),
        'secrets_dir': Path(secrets_dir),
        'data_dir': Path(data_dir),
        'google_creds': Path(secrets_dir) / 'google_calendar_credentials.json',
        'google_token': Path(secrets_dir) / 'google_calendar_token.json',
        'notion_creds': Path(secrets_dir) / 'notion_credentials.json'
    }

# File paths - cross-platform compatible
CURRENT_DIR = Path(__file__).parent
STANDALONE_DIR = CURRENT_DIR / 'Standalone'
CALENDAR_DIR = STANDALONE_DIR / 'Calendar'
TOKEN_PATH = CALENDAR_DIR / 'token.json'
CREDENTIALS_PATH = CALENDAR_DIR / 'credentials.json'

# Google Calendar Setup
def get_calendar_service() -> Any:
    """Initialize and return Google Calendar service with proper authentication."""
    paths = get_config_paths()
    
    creds = None
    try:
        if paths['google_token'].exists():
            creds = Credentials.from_authorized_user_file(str(paths['google_token']), SCOPES)
    except Exception as e:
        print("Error loading Google Calendar token")
        creds = None

    try:
        if not creds or not creds.valid:
            if creds and creds.expired and creds.refresh_token:
                creds.refresh(Request())
            else:
                if not paths['google_creds'].exists():
                    raise FileNotFoundError("Missing Google Calendar credentials file")
                flow = InstalledAppFlow.from_client_secrets_file(
                    str(paths['google_creds']), 
                    SCOPES,
                    redirect_uri='http://localhost:0'
                )
                creds = flow.run_local_server(port=0)
            
            paths['google_token'].parent.mkdir(parents=True, exist_ok=True)
            with open(paths['google_token'], 'w', encoding='utf-8') as token:
                token.write(creds.to_json())
    except Exception as e:
        print("Error during Google Calendar authentication")
        raise

    return build('calendar', 'v3', credentials=creds)

def adjust_overlapping_events(events):
    """Handle overlapping events within a single day."""
    sorted_events = sorted(events, key=lambda e: (e['start'], -e['duration']))
    adjusted_events = []
    last_end = None

    for event in sorted_events:
        if event['questionable']:
            adjusted_events.append(event)
            continue

        if last_end and event['start'] < last_end:
            if event['end'] <= last_end:
                continue  # Skip completely overlapped events
            event['start'] = last_end
            # Calculate duration in hours
            event['duration'] = (event['end'] - event['start']).total_seconds() / 3600

        adjusted_events.append(event)
        last_end = max(last_end, event['end']) if last_end else event['end']

    return adjusted_events

def calculate_event_hours(events, date):
    """Calculate total hours of events for a specific date, handling overlaps."""
    day_events = []
    central = pytz.timezone('US/Central')
    
    for event in events:
        if 'attendees' in event:
            if any(attendee.get('self') and attendee.get('responseStatus') == 'declined' 
                   for attendee in event['attendees']):
                continue

        start = event['start'].get('dateTime')
        end = event['end'].get('dateTime')
        
        if not start or not end:
            continue
            
        start_time = datetime.datetime.fromisoformat(start.replace('Z', '+00:00'))
        end_time = datetime.datetime.fromisoformat(end.replace('Z', '+00:00'))
        
        start_time_central = start_time.astimezone(central)
        end_time_central = end_time.astimezone(central)
        
        if start_time_central.date() == date:
            summary = event.get('summary', '').lower()
            questionable = any(word in summary for word in QUESTIONABLE_WORDS)
            
            if not questionable:
                duration = (end_time_central - start_time_central).total_seconds() / 3600  # Convert to hours
                day_events.append({
                    'start': start_time_central,
                    'end': end_time_central,
                    'duration': duration,  # Store as float hours
                    'questionable': questionable
                })
    
    adjusted_events = adjust_overlapping_events(day_events)
    total_hours = sum(event['duration'] for event in adjusted_events)
    return total_hours

async def fetch_chunk(session, headers, DATABASE_ID, chunk_start, chunk_end, semaphore):
    """Fetch a chunk of tasks asynchronously with rate limiting."""
    async with semaphore:
        chunk_totals = {}
        has_more = True
        next_cursor = None
        
        while has_more:
            payload = {
                'filter': {
                    'and': [
                        {
                            'property': 'Done?',
                            'checkbox': {
                                'equals': True
                            }
                        },
                        {
                            'property': 'Due Date',
                            'date': {
                                'on_or_after': chunk_start.isoformat(),
                                'on_or_before': chunk_end.isoformat()
                            }
                        }
                    ]
                }
            }
            
            if next_cursor:
                payload['start_cursor'] = next_cursor
            
            try:
                async with session.post(
                    f"https://api.notion.com/v1/databases/{DATABASE_ID}/query",
                    json=payload,
                    headers=headers
                ) as response:
                    if response.status == 429:
                        retry_after = int(response.headers.get('Retry-After', 1))
                        await asyncio.sleep(retry_after)
                        continue
                    
                    response.raise_for_status()
                    result = await response.json()
                    
                    for task in result.get('results', []):
                        due_date_prop = task['properties'].get('Due Date', {}).get('date')
                        if due_date_prop:
                            try:
                                # Handle both date-only and datetime values
                                date_str = due_date_prop.get('start')
                                if date_str:
                                    # Parse as datetime first
                                    try:
                                        date = datetime.datetime.fromisoformat(
                                            date_str.replace('Z', '+00:00')
                                        ).date()
                                    except ValueError:
                                        # If that fails, try parsing as date
                                        date = datetime.date.fromisoformat(date_str)
                                    
                                    time_block = task['properties'].get('Time Block (Min)', {}).get('number', 0)
                                    if time_block:
                                        chunk_totals[date] = chunk_totals.get(date, 0) + time_block
                            except ValueError:
                                continue
                    
                    has_more = result.get('has_more', False)
                    next_cursor = result.get('next_cursor')
                    
                    if has_more:
                        await asyncio.sleep(0.1)  # Small delay between pagination requests
                    
            except aiohttp.ClientError as e:
                print(f"Error fetching data chunk")  
                break
        
        return chunk_totals

async def fetch_all_chunks(headers, DATABASE_ID, date_chunks):
    """Fetch all chunks concurrently with rate limiting."""
    semaphore = asyncio.Semaphore(3)  # Limit to 3 concurrent requests
    async with aiohttp.ClientSession() as session:
        tasks = [
            fetch_chunk(session, headers, DATABASE_ID, chunk_start, chunk_end, semaphore)
            for chunk_start, chunk_end in date_chunks
        ]
        results = await asyncio.gather(*tasks)
    
    daily_totals = {}
    for chunk_totals in results:
        daily_totals.update(chunk_totals)
    
    return daily_totals

def fetch_local_completed_tasks_by_date_range(start_date, end_date):
    """Fetch completed tasks for a date range and return daily totals."""
    headers, DATABASE_ID = get_notion_headers()
    
    # Split the date range into smaller chunks for more efficient requests
    date_chunks = []
    current_date = start_date
    while current_date < end_date:
        chunk_end = min(current_date + datetime.timedelta(days=30), end_date)  # Reduced chunk size
        date_chunks.append((current_date, chunk_end))
        current_date = chunk_end + datetime.timedelta(days=1)
    
    # Run the asynchronous fetching using asyncio.run
    daily_totals = asyncio.run(fetch_all_chunks(headers, DATABASE_ID, date_chunks))
    
    return daily_totals

#currently unused, but useful to analysis of daily calendar and notion events
def get_daily_summary(target_date):
    """Get combined summary for a specific date."""
    # Get calendar hours
    service = get_calendar_service()
    central = pytz.timezone('US/Central')
    
    # Query for the specific day
    start_time = datetime.datetime.combine(target_date, datetime.time.min, tzinfo=central).astimezone(datetime.timezone.utc)
    end_time = datetime.datetime.combine(target_date, datetime.time.max, tzinfo=central).astimezone(datetime.timezone.utc)
    
    events_result = service.events().list(
        calendarId='primary',
        timeMin=start_time.isoformat(),
        timeMax=end_time.isoformat(),
        singleEvents=True,
        orderBy='startTime',
        maxResults=2500
    ).execute()
    
    events = events_result.get('items', [])
    calendar_hours = calculate_event_hours(events, target_date)
    calendar_minutes = int(calendar_hours * 60)
    
    # Get Notion tasks minutes
    target_datetime = datetime.datetime.combine(target_date, datetime.time.min)
    target_datetime = pytz.timezone('US/Central').localize(target_datetime)
    notion_minutes = fetch_local_completed_tasks_by_date_range(target_date, target_date)
    
    return calendar_minutes, notion_minutes

def adapt_date(date):
    """Convert date to string for SQLite storage."""
    return date.isoformat()

def convert_date(date_str):
    """Convert string from SQLite to date object."""
    return datetime.date.fromisoformat(date_str.decode())

# Register the adapters
sqlite3.register_adapter(datetime.date, adapt_date)
sqlite3.register_converter("DATE", convert_date)

def setup_database():
    """Setup SQLite database and tables."""
    paths = get_config_paths()
    db_path = paths['data_dir'] / 'dashboard_data.db'
    paths['data_dir'].mkdir(parents=True, exist_ok=True)
    
    conn = sqlite3.connect(db_path, detect_types=sqlite3.PARSE_DECLTYPES)
    cursor = conn.cursor()
    
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS calendar_events (
            date DATE PRIMARY KEY,
            minutes FLOAT
        )
    ''')
    
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS notion_tasks (
            date DATE PRIMARY KEY,
            minutes FLOAT
        )
    ''')
    
    conn.commit()
    return conn

def get_stored_data(conn, start_date, end_date):
    """Retrieve stored data from database for date range."""
    cursor = conn.cursor()
    
    # Get stored calendar data
    cursor.execute('''
        SELECT date, minutes FROM calendar_events 
        WHERE date BETWEEN ? AND ?
    ''', (start_date, end_date))
    calendar_stored = {date: minutes for date, minutes in cursor.fetchall()}
    
    # Get stored notion data
    cursor.execute('''
        SELECT date, minutes FROM notion_tasks 
        WHERE date BETWEEN ? AND ?
    ''', (start_date, end_date))
    notion_stored = {date: minutes for date, minutes in cursor.fetchall()}
    
    return calendar_stored, notion_stored

def store_calendar_data(conn, daily_totals):
    """Store calendar data in database."""
    cursor = conn.cursor()
    for date, minutes in daily_totals.items():
        cursor.execute('''
            INSERT OR REPLACE INTO calendar_events (date, minutes)
            VALUES (?, ?)
        ''', (date.isoformat(), minutes))
    conn.commit()

def store_notion_data(conn, daily_totals):
    """Store notion data in database."""
    cursor = conn.cursor()
    for date, minutes in daily_totals.items():
        cursor.execute('''
            INSERT OR REPLACE INTO notion_tasks (date, minutes)
            VALUES (?, ?)
        ''', (date.isoformat(), minutes))
    conn.commit()

# Break down main() into smaller functions
def fetch_and_process_data(start_date: datetime.date, end_date: datetime.date, conn: sqlite3.Connection):
    """
    Fetch and process both calendar and notion data for the given date range.
    
    Args:
        start_date: Start date for data collection
        end_date: End date for data collection
        conn: SQLite database connection
        
    Returns:
        tuple: Calendar data and Notion data dictionaries
    """
    calendar_stored, notion_stored = get_stored_data(conn, start_date, end_date)
    
    # Fetch calendar data
    service = get_calendar_service()
    dates_to_fetch = [
        date for date in (start_date + datetime.timedelta(days=x) 
        for x in range((end_date - start_date).days + 1)) 
        if date not in calendar_stored
    ]
    
    if dates_to_fetch:
        calendar_fetch_start = min(dates_to_fetch)
        if calendar_fetch_start <= end_date:
            new_calendar_totals = fetch_calendar_data(service, calendar_fetch_start, end_date)
            store_calendar_data(conn, new_calendar_totals)
            calendar_stored.update(new_calendar_totals)
    
    # Fetch Notion data
    dates_to_fetch = [
        date for date in (start_date + datetime.timedelta(days=x) 
        for x in range((end_date - start_date).days + 1)) 
        if date not in notion_stored
    ]
    
    if dates_to_fetch:
        notion_fetch_start = min(dates_to_fetch)
        if notion_fetch_start <= end_date:
            new_notion_totals = fetch_local_completed_tasks_by_date_range(notion_fetch_start, end_date)
            store_notion_data(conn, new_notion_totals)
            notion_stored.update(new_notion_totals)
            
    return calendar_stored, notion_stored

def create_visualization(dates, cal_minutes, notion_minutes, total_minutes):
    """Create and return the Plotly visualization figure."""
    fig = go.Figure()
    
    # Add calendar events bar
    fig.add_trace(go.Bar(
        x=dates,
        y=cal_minutes,
        name='Calendar Events',
        marker_color='#636EFA',
        yaxis='y'
    ))
    
    # Add notion tasks bar
    fig.add_trace(go.Bar(
        x=dates,
        y=notion_minutes,
        name='Notion Tasks',
        marker_color='white',
        yaxis='y'
    ))
    
    # Add moving average - just once
    window_size = 14
    moving_avg = calculate_moving_average(total_minutes, window_size)
    
    # Add moving average only once
    fig.add_trace(go.Scatter(
        x=dates,
        y=moving_avg,
        name='14-Day Moving Average',
        line=dict(color='gray', width=5),
        mode='lines',
        yaxis='y'
    ))
    
    # Add second trace for right axis scaling
    fig.add_trace(go.Scatter(
        x=dates,
        y=moving_avg,  # Use exact same values as first trace
        showlegend=False,
        line=dict(color='gray', width=5),
        mode='lines',
        yaxis='y2'
    ))
    
    # Update layout
    fig.update_layout(
        title='Daily Time Distribution',
        barmode='stack',
        template='plotly_dark',
        yaxis=dict(
            title='Minutes',
            side='left',
            showgrid=True,
            range=[0, 1440]  # Set fixed range for minutes (24 hours * 60 minutes)
        ),
        yaxis2=dict(
            title='Hours',
            overlaying='y',
            side='right',
            showgrid=False,
            range=[0, 24],  # Set fixed range for hours
            scaleratio=1/60  # Scale minutes to hours
        ),
        showlegend=True,
        legend=dict(
            yanchor="top",
            y=0.99,
            xanchor="right",
            x=0.99
        ),
        margin=dict(t=30, l=60, r=60, b=60)
    )
    
    fig.update_xaxes(tickangle=45)
    return fig

def fetch_calendar_data(service, start_date, end_date):
    """
    Fetch and process calendar data for the given date range.
    
    Args:
        service: Google Calendar service object
        start_date: Start date for fetching events
        end_date: End date for fetching events
        
    Returns:
        dict: Daily totals of calendar minutes
    """
    # Convert dates to UTC for API request
    start_datetime = datetime.datetime.combine(start_date, datetime.time.min)
    end_datetime = datetime.datetime.combine(end_date, datetime.time.max)
    start_utc = pytz.timezone('US/Central').localize(start_datetime).astimezone(datetime.timezone.utc)
    end_utc = pytz.timezone('US/Central').localize(end_datetime).astimezone(datetime.timezone.utc)
    
    events_result = service.events().list(
        calendarId='primary',
        timeMin=start_utc.isoformat(),
        timeMax=end_utc.isoformat(),
        singleEvents=True,
        orderBy='startTime',
        maxResults=2500
    ).execute()
    
    events = events_result.get('items', [])
    
    # Process events into daily totals
    daily_totals = {}
    current_date = start_date
    while current_date <= end_date:
        daily_totals[current_date] = calculate_event_hours(events, current_date) * 60  # Convert hours to minutes
        current_date += datetime.timedelta(days=1)
    
    return daily_totals

def prepare_visualization_data(start_date, end_date, calendar_stored, notion_stored):
    """
    Prepare data for visualization by aligning calendar and notion data.
    
    Args:
        start_date: Start date of the range
        end_date: End date of the range
        calendar_stored: Dictionary of calendar minutes by date
        notion_stored: Dictionary of notion minutes by date
        
    Returns:
        tuple: (dates, calendar_minutes, notion_minutes, total_minutes)
    """
    dates = []
    cal_minutes = []
    notion_minutes = []
    total_minutes = []
    
    current_date = start_date
    while current_date <= end_date:
        dates.append(current_date)
        
        # Get calendar minutes for the day (default to 0 if none)
        cal_mins = calendar_stored.get(current_date, 0)
        cal_minutes.append(cal_mins)
        
        # Get notion minutes for the day (default to 0 if none)
        notion_mins = notion_stored.get(current_date, 0)
        notion_minutes.append(notion_mins)
        
        # Calculate total minutes
        total_minutes.append(cal_mins + notion_mins)
        
        current_date += datetime.timedelta(days=1)
    
    return dates, cal_minutes, notion_minutes, total_minutes

def calculate_moving_average(data, window_size):
    """
    Calculate trailing moving average using pandas.
    
    Args:
        data: List of values
        window_size: Size of the moving window
        
    Returns:
        list: Moving averages
    """
    # Convert to pandas series
    series = pd.Series(data)
    
    # Calculate trailing moving average
    moving_avg = series.rolling(
        window=window_size,
        min_periods=1  # Start calculating as soon as we have at least 1 value
    ).mean()
    
    # Convert back to list
    return moving_avg.tolist()

def get_notion_headers():
    """Load Notion API credentials from environment or file"""
    paths = get_config_paths()
    
    notion_token = os.getenv('NOTION_TOKEN')
    notion_database_id = os.getenv('NOTION_DATABASE_ID')
    
    if not (notion_token and notion_database_id):
        try:
            with open(paths['notion_creds'], 'r') as f:
                creds = json.load(f)
                notion_token = creds.get('token')
                notion_database_id = creds.get('database_id')
        except FileNotFoundError:
            raise Exception("Notion credentials not found. Set NOTION_TOKEN and NOTION_DATABASE_ID environment variables or create a notion_credentials.json file.")
    
    return {
        'Authorization': f'Bearer {notion_token}',
        'Notion-Version': NOTION_API_VERSION,
        'Content-Type': 'application/json'
    }, notion_database_id

def main():
    """Main execution function."""
    local_tz = datetime.datetime.now().astimezone().tzinfo  # Use system timezone
    today = datetime.datetime.now(local_tz).date()
    start_date = START_DATE
    end_date = today - datetime.timedelta(days=1)
    
    print(f"Analyzing time data from {start_date} to {end_date}")
    
    conn = setup_database()
    try:
        calendar_stored, notion_stored = fetch_and_process_data(start_date, end_date, conn)
        
        dates, cal_minutes, notion_minutes, total_minutes = prepare_visualization_data(
            start_date, end_date, calendar_stored, notion_stored)
        
        fig = create_visualization(dates, cal_minutes, notion_minutes, total_minutes)
        return fig
        
    finally:
        conn.close()

if __name__ == '__main__':
    fig = main()
    fig.show()  # Only show if run directly
